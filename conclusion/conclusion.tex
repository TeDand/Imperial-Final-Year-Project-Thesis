\chapter{Conclusion and Further Work} \label{chap:conclusion_and_further_work}

To conclude, the testing done with the two classification pipelines show that there are significant benefits to working within the neuromorphic paradigm as opposed to with classic frame-based cameras. With the same networks, performance appears to be superior when analysing event streams rather than video frames. Secondly, the two-phase intensity reconstruction pipelines show promise, being able to harness the wealth of existing networks that exist for video classification. However, the performance with the same classification networks directly on the events rather than the video reconstructions tended to have better performance, perhaps due to the loss of high-frequency data and when creating the intensity maps. This is however open to interpretation, since the models used to classify the reconstructions are relatively simple. The reconstructions do show that the benefits of event-based cameras can be retained even when working with intensity videos, as the reconstruction networks produce high fidelity outputs even when recording videos with lots of motion or high dynamic range of light intensities. This means that the reconstructed videos are often more appropriate for classification that if a video was taken with a frame-based camera. \color{red} TODO: Write about performance of spiking neural networks. \color{black}

\section{Further Work}

Having reached the end of the project, it is important to note the limitations (such as computing power and available time) that need to be acknowledged. As such, there are some key areas in which there is scope for further research and development. These include;

\begin{enumerate}
    \item With a more capable setup and time to test the networks, there is the opportunity to create more intensive networks. As well as this larger batch sizes can be used for more stable training with higher RAM available.
    \item Compare the performance of the reconstructed pipeline like-for-like against a video stream from a frame-based camera. This has been omitted from this project due to time constraints and lack of available datasets.
    \item Change E2VID parameters so that resulting reconstructed video is of a higher framerate.
    \item Test the performance of the described networks and pipelines on more readily available datasets to make sure that the findings apply to other environments. Intensity reconstructions may be more beneficial for more complex tasks.
    \item Test performance gain with custom frame integration method with all networks.
    \item Look more at the use of natural language processing techniques when working with event streams.
    \item Create more spiking neural networks, perhaps from scratch rather than converting regular ANNs. Further testing needs to be done in this area.
    \item Test the performance of the end-to-end event classification networks when frame-integration is done asynchronously as well as synchronously (as described in \cref{ssec:frame_integration}). Comparisons between the two forms of integration, as well as effect of having smaller time-slices per frame need to be tested.
    \item Create spiking neural networks based on more complex ANN networks. This involves creating approximations to other, more complex layers such as LSTM and GRU layers.
    \item Implement spiking neural networks on neuromorphic hardware. This also opens up the possibility of real-time inference.
    \item Create a spiking version of the intensity reconstruction algorithms to check if they perform well.
\end{enumerate}

\section{Similar External Work}

A method, similar to the custom frame integration proposed in \cref{sssec:custom_frame_integration_implementation}, that aimed to preserve temporal resolution was proposed by Lo\"ic Cordone \textit{et al.}, who proposed `voxel cubes'\cite{MiniVovelCubes}. For this method there were still binary events in every channel, but there were more than two channels so that the events in each time-slice could be subdivided into each channel. When compared to this method, the temporal information can be stored in the same way with the novel method proposed in this project, while keeping data size small since it is just a one-channel image. 

\color{red}
\begin{itemize}
    \item TODO: Look at these: \url{https://arxiv.org/pdf/2205.04339.pdf} and \url{https://arxiv.org/pdf/2104.12579.pdf} COULD MEAN WORK IS NOT STATE OF THE ART UGHHHH. 
    \item \url{https://arxiv.org/pdf/2205.04339.pdf} using channel dimension could be future work.
\end{itemize}
\color{black}
